(window.webpackJsonp=window.webpackJsonp||[]).push([[49],{433:function(t,a,s){"use strict";s.r(a);var e=s(10),r=Object(e.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("p",[t._v("本文所有内容均在 GNU C++ (64位) 里瞎搞出来，有很多猜测，仅供参考。")]),t._v(" "),a("h2",{attrs:{id:"_1-如何定义"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-如何定义"}},[t._v("#")]),t._v(" 1. 如何定义")]),t._v(" "),a("div",{staticClass:"language-cpp extra-class"},[a("pre",{pre:!0,attrs:{class:"language-cpp"}},[a("code",[t._v("vector"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allocator"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v("\ndeque"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allocator"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v("\nlist"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allocator"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v("\nforward_list"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allocator"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v("\n\nset"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" less"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allocator"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v("\nmap"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" U"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" less"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allocator"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("pair"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" U"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\nunordered_set"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" hash"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" equal_to"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allocator"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v("\nunordered_map"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" U"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" hash"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" equal_to"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allocator"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("pair"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" U"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 省略 multiset, multimap, unordered_multiset, unordered_multimap")]),t._v("\n\nbasic_string"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" char_traits"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allocator"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v("\nbasic_stringstream"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" char_traits"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allocator"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// using string = basic_string<char>")]),t._v("\n\nqueue"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" deque"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v("\nstack"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" deque"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v("\npriority_queue"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" vector"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" less"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v("\n\narray"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" N"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\nbitset"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("N"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),a("h2",{attrs:{id:"_2-内存分配"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-内存分配"}},[t._v("#")]),t._v(" 2. 内存分配")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"center"}},[t._v("容器")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("sizeof")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("扩容方式")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("内存释放方式")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("vector")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("24")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("每次两倍")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不释放")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("deque")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("80")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("初始512字节，每次512字节+少量额外内存")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("基本释放")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("list")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("16")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("要多少申请多少")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不留多余内存")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("forward_list")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("8")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("要多少申请多少")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不留多余内存")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("(multi)set/map")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("48")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("要多少申请多少")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不留多余内存")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("unordered_(multi)set/map")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("56")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("要多少申请多少+桶的内存")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("桶不释放，其余不留多余内存")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("string")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("8")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("每次两倍+少量额外内存")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不释放")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("stringstream")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("368")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("初始512字节，每次两倍+少量额外内存")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不释放")])])])]),t._v(" "),a("ul",[a("li",[t._v("queue, stack, priority_queue 是由其他容器改造过来的（第二个模板参数），queue, stack 默认是 deque，priority_queue 默认是 vector。")]),t._v(" "),a("li",[t._v("array, bitset 都是固定长度，没有内存分配器，估计和数组行为一致。")]),t._v(" "),a("li",[t._v("list, forward_list, set, map 这些链表数据结构（unordered 每个桶也是链表），每个结点的指针的内存不通过自定义内存分配器分配。目前初步估计 set / map 的每个结点有额外 24 字节（通过鸡兔同笼法），其余懒得算。")]),t._v(" "),a("li",[a("code",[t._v("vector<bool>")]),t._v(" 很奇葩，最好不用。")])]),t._v(" "),a("h2",{attrs:{id:"_3-时间复杂度"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-时间复杂度"}},[t._v("#")]),t._v(" 3. 时间复杂度")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("list")]),t._v(" 的 "),a("code",[t._v("size()")]),t._v(" 是 "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",[a("semantics",[a("mrow",[a("mi",[t._v("O")]),a("mo",[t._v("(")]),a("mi",[t._v("n")]),a("mo",[t._v(")")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("O(n)")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"strut",staticStyle:{height:"0.75em"}}),a("span",{staticClass:"strut bottom",staticStyle:{height:"1em","vertical-align":"-0.25em"}}),a("span",{staticClass:"base textstyle uncramped"},[a("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.02778em"}},[t._v("O")]),a("span",{staticClass:"mopen"},[t._v("(")]),a("span",{staticClass:"mord mathit"},[t._v("n")]),a("span",{staticClass:"mclose"},[t._v(")")])])])]),t._v(" 的！（"),a("code",[t._v("forward_list")]),t._v(" 干脆不定义这个函数），想用 "),a("code",[t._v("list")]),t._v(" 代替 "),a("code",[t._v("deque")]),t._v(" 的同学要注意这个坑点。（事实上 "),a("code",[t._v("list::size()")]),t._v(" 在 "),a("code",[t._v("C++ 11")]),t._v(" 标准里已经要求 "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",[a("semantics",[a("mrow",[a("mi",[t._v("O")]),a("mo",[t._v("(")]),a("mn",[t._v("1")]),a("mo",[t._v(")")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("O(1)")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"strut",staticStyle:{height:"0.75em"}}),a("span",{staticClass:"strut bottom",staticStyle:{height:"1em","vertical-align":"-0.25em"}}),a("span",{staticClass:"base textstyle uncramped"},[a("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.02778em"}},[t._v("O")]),a("span",{staticClass:"mopen"},[t._v("(")]),a("span",{staticClass:"mord mathrm"},[t._v("1")]),a("span",{staticClass:"mclose"},[t._v(")")])])])]),t._v(" 了，但是实际不一定）")]),t._v(" "),a("li",[a("code",[t._v("array / bitset")]),t._v(" 的 "),a("code",[t._v("swap()")]),t._v(" 是 "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",[a("semantics",[a("mrow",[a("mi",[t._v("O")]),a("mo",[t._v("(")]),a("mi",[t._v("n")]),a("mo",[t._v(")")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("O(n)")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"strut",staticStyle:{height:"0.75em"}}),a("span",{staticClass:"strut bottom",staticStyle:{height:"1em","vertical-align":"-0.25em"}}),a("span",{staticClass:"base textstyle uncramped"},[a("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.02778em"}},[t._v("O")]),a("span",{staticClass:"mopen"},[t._v("(")]),a("span",{staticClass:"mord mathit"},[t._v("n")]),a("span",{staticClass:"mclose"},[t._v(")")])])])]),t._v(" 的（要把它当 C 的数组看待）。")]),t._v(" "),a("li",[t._v("其他复杂度还没发现不正常的。")])]),t._v(" "),a("h2",{attrs:{id:"_4-迭代器"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-迭代器"}},[t._v("#")]),t._v(" 4. 迭代器")]),t._v(" "),a("ul",[a("li",[t._v("由其他容器改造的容器（queue, stack, priority_queue）都没有迭代器。")]),t._v(" "),a("li",[t._v("bitset 没有迭代器。")]),t._v(" "),a("li",[t._v("stringstream 没有迭代器（不考虑特殊迭代器）。")])]),t._v(" "),a("h2",{attrs:{id:"_5-vector-行为分析"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-vector-行为分析"}},[t._v("#")]),t._v(" 5. vector 行为分析")]),t._v(" "),a("p",[t._v("引用了我的一篇博客园文章。")]),t._v(" "),a("blockquote",[a("p",[t._v("众所周知，vector 的 "),a("code",[t._v("size()")]),t._v(" 其实并不代表它占用的空间，它实际占用空间可以用 "),a("code",[t._v("capacity()")]),t._v(" 查看。")]),t._v(" "),a("p",[t._v("众所周知，"),a("code",[t._v("push_back()")]),t._v(" 时，如果 "),a("code",[t._v("size == capacity")]),t._v(" 则会使 capacity 从 0 变 1 或者变为原来两倍，当然如果 "),a("code",[t._v("size<capacity")]),t._v(" 则不会触发内存分配。")]),t._v(" "),a("p",[t._v("众(gui)所(cai)周(zhi)知(dao)，一旦触发内存分配，原来的指针或者迭代器失效，因为 vector 的所有内容搬迁到新的内存里了。")]),t._v(" "),a("p",[t._v("你可能觉得 "),a("code",[t._v("push_back()")]),t._v(" 奇慢无比，那倒也不至于，因为平均下来 "),a("code",[t._v("push_back()")]),t._v(" 复杂度确实是 "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",[a("semantics",[a("mrow",[a("mi",[t._v("O")]),a("mo",[t._v("(")]),a("mn",[t._v("1")]),a("mo",[t._v(")")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("O(1)")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"strut",staticStyle:{height:"0.75em"}}),a("span",{staticClass:"strut bottom",staticStyle:{height:"1em","vertical-align":"-0.25em"}}),a("span",{staticClass:"base textstyle uncramped"},[a("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.02778em"}},[t._v("O")]),a("span",{staticClass:"mopen"},[t._v("(")]),a("span",{staticClass:"mord mathrm"},[t._v("1")]),a("span",{staticClass:"mclose"},[t._v(")")])])])]),t._v("。")]),t._v(" "),a("p",[t._v("当然慢也是有一定道理的，因为如果直接用 vector 数组作为邻接表来存图，效率并不理想。")]),t._v(" "),a("p",[t._v("比如我们定义了 "),a("code",[t._v("vector<int> a[100010];")]),t._v("，随机建边的时候就会疯狂触发内存分配导致愉快地 TLE。（不过图论题这么毒瘤的也不常见）")]),t._v(" "),a("p",[t._v("解决方法是前向星或者手写分配器。如果不手写分配器用 list 替代 vector 貌似更慢了。（虽然我也不知道为什么，另外 forward_list 和 vector 差不多的亚子）")]),t._v(" "),a("p",[t._v("众(gui)所(cai)周(zhi)知(dao)，不止 push_back()，像 "),a("code",[t._v("resize()")]),t._v(", "),a("code",[t._v("reserve()")]),t._v(" 等都会触发内存分配。")]),t._v(" "),a("p",[t._v("众(gui)所(cai)周(zhi)知(dao)，像 "),a("code",[t._v("clear()")]),t._v(", "),a("code",[t._v("pop_back()")]),t._v(" 等并不会释放内存（也就不会使 capacity 变小），只有 "),a("code",[t._v("shrink_to_fit()")]),t._v(" 等少数几个操作才能使 capacity 变小。因此有些不得已的情况会用 "),a("code",[t._v("a = vector<int>()")]),t._v(" 来代替 "),a("code",[t._v("a.clear()")]),t._v("。")]),t._v(" "),a("p",[t._v("当然也有可能 "),a("code",[t._v("a.clear()")]),t._v(" 导致 MLE，"),a("code",[t._v("a = vector<int>()")]),t._v(" 导致 TLE（笑）。")]),t._v(" "),a("p",[t._v("众(gui)所(cai)周(zhi)知(dao)，vector 对内存分配的惰性其实是为了效率考虑的，它很好地规避了频繁的分配释放空间。vector 满足了很多常见需求。但是像图论等某些地方还是不能偷懒，还得花点功夫写分配器，或者用前向星、手写 queue 这种朴素方法代替 STL。")]),t._v(" "),a("p",[t._v("手写分配器的方法如下：")]),t._v(" "),a("div",{staticClass:"language-cpp extra-class"},[a("pre",{pre:!0,attrs:{class:"language-cpp"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("char")]),t._v(" space"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10000000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("sp"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("space"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("template")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("typename")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("T")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("struct")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("allc")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token base-clause"}},[a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("allocator")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("T")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("allc")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("template")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("typename")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("U")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("allc")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" allc"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("U"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("template")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("typename")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("U")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n    allc"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("operator")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" allc"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("U"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("template")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("typename")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("U")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("struct")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("rebind")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("typedef")]),t._v(" allc"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("U"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" other"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("inline")]),t._v(" T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("allocate")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("size_t n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        T "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("res"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("sp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        sp"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v("n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("sizeof")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" res"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("inline")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("deallocate")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" p"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("size_t n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nvector"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("allc"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])])]),t._v(" "),a("h2",{attrs:{id:"_6-deque-行为分析"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-deque-行为分析"}},[t._v("#")]),t._v(" 6. deque 行为分析")]),t._v(" "),a("p",[t._v("引用了我的一篇博客园文章。")]),t._v(" "),a("blockquote",[a("p",[t._v("上次队友因为 deque 导致 MLE 惨案，今天好奇想要看看 deque 是怎么操作的（非专业分析）。")]),t._v(" "),a("p",[t._v("我重载了 allocator 然后输出一下内存占用和释放情况，发现如下现象：")]),t._v(" "),a("ul",[a("li",[t._v("就算不使用 deque，只要声明了 deque 就占用 512 字节（比如 128 个 int，64 个 long long）（如果无法整除，比如 "),a("code",[t._v("tuple<int,int,int>")]),t._v("，512 无法整除 12，那会比 512 字节少一点），另外占用少量字节用于索引。")]),t._v(" "),a("li",[t._v("如果数据量超出当前的 size，会多申请 512 字节，每次都是 512 亘古不变。")]),t._v(" "),a("li",[t._v("当然，所有的块显然是不连续的，因此有如下猜测：索引存在的意义就是让 deque 的随机访问控制在 "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",[a("semantics",[a("mrow",[a("mi",[t._v("O")]),a("mo",[t._v("(")]),a("mn",[t._v("1")]),a("mo",[t._v(")")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("O(1)")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"strut",staticStyle:{height:"0.75em"}}),a("span",{staticClass:"strut bottom",staticStyle:{height:"1em","vertical-align":"-0.25em"}}),a("span",{staticClass:"base textstyle uncramped"},[a("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.02778em"}},[t._v("O")]),a("span",{staticClass:"mopen"},[t._v("(")]),a("span",{staticClass:"mord mathrm"},[t._v("1")]),a("span",{staticClass:"mclose"},[t._v(")")])])])]),t._v(" 复杂度内，同样索引也可以灵活分配 push_back、push_front 所需要的内存。")]),t._v(" "),a("li",[t._v("另外 "),a("code",[t._v("clear()")]),t._v(" 是真的会释放内存的，而不是和 vector 一样保留内存。")])])])])}),[],!1,null,null,null);a.default=r.exports}}]);